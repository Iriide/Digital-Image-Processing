{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"bY2cnBzEoHck"},"source":["# Klasyfikacja znaków drogowym z wykorzystaniem DCNN\n","\n","Uwaga. Ćwiczenie powstało w oparciu o następujący [tutorial](https://www.pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/).\n","Osoby zainteresowane tematem - moim zdaniem (Tomasz Kryjak) powinien to być każdy z Państwa -- zachęcam do prześledzenia tego dokumentu bardziej szczegółowo.\n","\n","Inne podobne tutoriale:\n","- https://chsasank.github.io/keras-tutorial.html\n","- https://towardsdatascience.com/building-a-road-sign-classifier-in-keras-764df99fdd6a\n","\n","\n","To krótkie ćwicznie nie zastąpi pełnego kursu z AI, ale powinno pozwolić poznać podstawowe etapy związane z inżynierskim wykorzystaniem głębokich konwolucyjnych sieci neuronowych (DCNN - Deep Convolutional Neural Network).\n","\n","## Założenia (v 1.0)\n","\n","Poniższy notatnik jest kompletny i \"do uruchomienia\".\n","Jedyne wyzwania (niekoniecznie trywialne) to sprawy techniczne.\n","W przyszłości będzie to ulegało zmianom.\n","\n","Uwaga. Czas obliczeń może być znaczny, ale można go wykorzystać np. na czytanie wskazanego tutoriala, tudzież analizę kodu :).\n","\n","## Instalacja, sprawy techniczne\n","\n","Notatnik do działania potrzebuje pakietów:\n","- OpenCV\n","- NumPy\n","- scikit-learn\n","- scikit-image\n","- imutils\n","- matplotlib\n","- TensorFlow 2.0 (CPU or GPU)\n","\n","Opcje uruchomienia są dwie:\n","- Google Colaboratory - tam wszystko jest zainstalowane + mamy zasoby obliczeniowe, ale trzeba nieco pokombinować z dostarczeniem danych. Opis poniżej. Jest też opcja rekomendowana.\n","- lokalnie (instalacja pakietów via *pip* lub poprzez PyCharm).\n","\n","Dodatkowo należy pobrać bazę danych [GTSRB](https://drive.google.com/file/d/1EQ-tyVHIdVaa4_1bob1zv8zgaVmvyyqV/view?usp=sharing) (German Traffic Sign Recognition Benchmark) (300 MB).\n","Baza zawiera ponad 50000 obrazków dal 43 klas znaków.\n","Ma też dwie istotne wady:\n","- różna liczba przykładów z poszczególnych klas (od 180 do ponad 2000),\n","- część znaków stanowi duże wyzwanie (słaba jakość, kontrast) - uczciwie mówiąć, to niektóre trudno rozpoznać.\n","\n","Nie wchodząc w zbytnie szczegóły.\n","Sieć DCNN \"się uczy\" (jest uczona) na podstawie przykładów.\n","Podobnie jak uczymy się my.\n","I teraz np. jeśli rozwiążemy 10 zadań nt. całek i 100 na temat pochodnych, to co na egzaminie co wyjdzie lepiej ?\n","Stąd tego typu dysproporcja stanowi problem.\n","Słaba jakość zdjęć też utrudnia uczenie.\n","\n","\n","W przypadku przetwarzania lokalnego bazę należy rozpakować.\n","\n","\n","## Informacje wstępne DCNN\n","\n","Co to jest sieć DCNN (Deep Convolutional Neural Network) ?\n","\n","Model naśladujący działanie ludzkiego mózgu (tu konkretnie sposobu przetwarzania informacji wizyjnej).\n","Przedstawienie całej teorii w notatniku nie jest specjalnie wygodne -- zainteresowane osoby odsyłam do obszernej literatury.\n","Bez wchodzenia w szczegóły, sieć można traktować jako czarną skrzynkę, która na wejściu dostaje obraz, a na wyjściu wyniki (klasy obiektów).\n","\n","Przy czym sieć trzeba nauczyć.\n","W uproszczeniu proces polega na tym, że prezentujemy sieci obraz, otrzymujemy jakiś wynik, porównujemy go z pożądanym i wg. specjalnego algorytmu modyfikujemy parametry sieci (tzw. wsteczna propogacja błędu).\n","Uwaga. To jest tzw. uczenie nadzorowane (z nauczycielem).\n","Istnieje tez uczenie bez nauczyciela (sieci samouczące) oraz ze wspomaganiem (reinforcement learing).\n","Szczególnie to drugie jest bardzi ciekwe - warto sobie o tym poczytać.\n","To ta metodologia stoi za sukcesami AlphaGo (w grze Go), czy w Starcrafta.\n","\n","Mając nauczoną sieć, można przeprowadzić tzw. wnioskowanie (ang. *inference*).\n","\n","Warto też wiedzieć, że sieci konwolucyjne to jest jedna z możliwości, dedykowana do obrazów.\n","Dla innych zagadnienień stosowane są inne modele.\n","Ponadto w ramach samych DCNN występuje wiele różnych rozwiązań, choć są one zbudowane z mniej więcej podobnych \"klocków\".\n","\n","Źródła dodatkowych informacji:\n","- https://en.wikipedia.org/wiki/Convolutional_neural_network\n","- https://d2l.ai/\n","- kursy na Coursera\n","- a tak na prawdę to jest tego bardzo dużo.\n","\n","\n","## Co my dzisiaj zrobimy ?\n","\n","Przejdziemy przez następujące kroki:\n","- utworzenie modelu (definicja architektury sieci),\n","- implementacja funkcji do przygotowania zbioru uczącego,\n","- przygotowanie danych,\n","- uczenie,\n","- analiza wyników uczenia,\n","- testy: wnioskowanie.\n","\n","Bardziej szczegółowe komentarze w tekście.\n","\n"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"fN5Jt-mooHcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705327591755,"user_tz":-60,"elapsed":30482,"user":{"displayName":"xy z","userId":"08668859455928206610"}},"outputId":"5687e90e-149e-4e76-906e-0c1798c08f54"},"source":["# Definicja architektury sieci\n","\n","# Potrzebne biblioteki\n","\n","!sudo pip3 install tensorflow\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import classification_report\n","from skimage import transform\n","from skimage import exposure\n","from skimage import io\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","import os\n","import pickle\n","import requests\n","\n","\n","# Siec do klasyfikacji\n","# Składa się z:\n","# 5 warstw konwolucyjnych - Conv2D, po nich funkcja aktywacji (relu), normalizacja oraz podpróbkowanie (zmiana rozdzielczości).\n","# 2 warstwy tzw. w pełni połączonych\n","\n","# Uwaga. Sieć ta jest zbliżona do rozwiązana AlexNet (https://en.wikipedia.org/wiki/AlexNet).\n","# Natomiast sam AlexNet to jedna z pierwszych (a na pewno najbardziej znanych) sieci konwolucyjnych.\n","# To m.in. sukses tego rozwiązania w konkursie  ImageNet Large Scale Visual Recognition Challenge.\n","# Artykluł ja opisujący ma ponad 70000 cytowań.\n","\n","class TrafficSignNet:\n","\t@staticmethod\n","\tdef build(width, height, depth, classes):\n","\t\tmodel = Sequential()\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","    # CONV => RELU => BN => POOL\n","\t\tmodel.add(Conv2D(8, (5, 5), padding=\"same\", input_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n","\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\t\t# second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # first set of FC => RELU layers\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(128))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization())\n","\t\tmodel.add(Dropout(0.5))\n","\t\t# second set of FC => RELU layers\n","\t\tmodel.add(Flatten())\n","\t\tmodel.add(Dense(128))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization())\n","\t\tmodel.add(Dropout(0.5))\n","\t\t# Klasyfikator softmax\n","\t\tmodel.add(Dense(classes))\n","\t\tmodel.add(Activation(\"softmax\"))\n","\t\t#\n","\t\treturn model\n","\n","print(\"[INFO] Model created\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","[INFO] Model created\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"vXvPKNQMoHcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705327591756,"user_tz":-60,"elapsed":6,"user":{"displayName":"xy z","userId":"08668859455928206610"}},"outputId":"c915ec8f-1a7f-430a-902a-3704efcba9bb"},"source":["# Funkcja do przygotowania obrazów\n","\n","def load_split(basePath, csvPath):\n","    # Inicjalizacja list dla danych i etykiet (klas znaków)\n","    data = []\n","    labels = []\n","\t# Wczytanie zawartości pliku CVS z opisem danych, pominięcie pierwszej linii.\n","    rows = open(csvPath).read().strip().split(\"\\n\")[1:]\n","    # Wymieszanie przykładów uczących\n","    random.shuffle(rows)\n","\n","    # Pętla po przykładach uczących\n","    for (i, row) in enumerate(rows):\n","\t    # Wypisanie informacji co 1000 przykładów\n","        if i > 0 and i % 1000 == 0:\n","           print(\"[INFO] processed {} total images\".format(i))\n","\n","        # Dla danego rzędu pozyskujemy etykietę (label) oraz ścieżkę do pliku\n","        (label, imagePath) = row.strip().split(\",\")[-2:]\n","\t  \t# \"Skompletowanie\" ścieżki i wczytanie obrazu\n","        imagePath = os.path.sep.join([basePath, imagePath])\n","        image = io.imread(imagePath)\n","        # Przeskalowanie do rozmiaru 32x32 i poprawa kontrastu metodą CLHAE (Contrast Limited Adaptive Histogram Equalization)\n","        image = transform.resize(image, (32, 32))\n","        image = exposure.equalize_adapthist(image, clip_limit=0.1)\n","        # Dodanie obrazka i etykiekt do listy\n","        data.append(image)\n","        labels.append(int(label))\n","\n","    # Konwersja danych i etykiet na tablice NumPy\n","    data = np.array(data)\n","    labels = np.array(labels)\n","\t  # Zwracamy dane i etykiety (w formie krotki)\n","    return (data, labels)\n","\n","print(\"[INFO] Function defined\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Function defined\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"tbbFlWRnoHct","colab":{"base_uri":"https://localhost:8080/","height":991},"executionInfo":{"status":"error","timestamp":1705327608875,"user_tz":-60,"elapsed":17124,"user":{"displayName":"xy z","userId":"08668859455928206610"}},"outputId":"328d208b-27c7-4adc-b9aa-6b8c0b512507"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","!pip3 install --upgrade gdown\n","\n","# Pobranie pliku z nazwami znakow\n","\n","url = 'https://raw.githubusercontent.com/vision-agh/poc_sw/master/14_TSR_DCNN/'\n","\n","fileNames = [\"signnames.csv\"]\n","for fileName in fileNames:\n","  if not os.path.exists(fileName):\n","      r = requests.get(url + fileName, allow_redirects=True)\n","      open(fileName, 'wb').write(r.content)\n","\n","# Przygotowanie danych\n","\n","# Jeśli ktoś używa Google Colab\n","# 1. Wgrać plik gtsrb.zip na dysk googla\n","# 2. Podmontować dysk.\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","!gdown 1b-ijBmRyyyL6ypu9Silp5RZz90sFc4VD&confirm=t\n","\n","# 3. Zainstlować zip i rozpakować plik\n","# Uwaga ustawić scieżke\n","!apt install unzip\n","!unzip 'gtsrb.zip'\n","\n","\n","# Jeśli ktoś pracuje lokalnie, to trzeba tu ustawić ścieżkę.\n","# Ścieżka do danych\n","dataset = \"gtsrb/\"\n","\n","# Wczytanie nazw etykiet\n","labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n","labelNames = [l.split(\",\")[0] for l in labelNames]\n","\n","# Ustawienie ścieżki do zbioru uczącego i testowego\n","trainPath = os.path.sep.join([dataset, \"Train.csv\"])\n","testPath = os.path.sep.join([dataset, \"Test.csv\"])\n","\n","# Wczytanie danych uczących i testowych (dość długo trwa).\n","print(\"[INFO] loading training and testing data...\")\n","(trainX, trainY) = load_split(dataset, trainPath)\n","(testX, testY) = load_split(dataset, testPath)\n","\n","# Przeskalowanie danych do zakresu [0, 1]\n","trainX = trainX.astype(\"float32\") / 255.0\n","testX = testX.astype(\"float32\") / 255.0\n","\n","# Zakodowanie etykiet danych uczących i testowych w formacie *one-hot* (z całego wektora tylko jedna wartość to 1, reszta 0).\n","# To wprost koresponduje z wyjściem z sieci (warstwa softmax), gdzie otrzymujemy wektor w długości takiej, ile mamy klas (tu 43) i wyszukujemy w nim maksimum.\n","numLabels = len(np.unique(trainY))\n","trainY = to_categorical(trainY, numLabels)\n","testY = to_categorical(testY, numLabels)\n","\n","# Zapis danych uczących i testowych do pliku (żeby tego ew. nie powtarzać), jak coś na dalszym etapie pójdzie nie tak.\n","with open('train_test.pickle', 'wb') as f:\n","    pickle.dump([trainX, trainY, testX, testY], f)\n","\n","print(\"[INFO] saving training and testing data...\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n","Collecting gdown\n","  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.6.6\n","    Uninstalling gdown-4.6.6:\n","      Successfully uninstalled gdown-4.6.6\n","Successfully installed gdown-4.7.1\n","Access denied with the following error:\n","\n"," \tCannot retrieve the public link of the file. You may need to change\n","\tthe permission to 'Anyone with the link', or have had many accesses. \n","\n","You may still be able to access the file from the browser:\n","\n","\t https://drive.google.com/uc?id=1b-ijBmRyyyL6ypu9Silp5RZz90sFc4VD \n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","unzip is already the newest version (6.0-26ubuntu3.1).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n","unzip:  cannot find or open gtsrb.zip, gtsrb.zip.zip or gtsrb.zip.ZIP.\n","[INFO] loading training and testing data...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'gtsrb//Train.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1891543ed625>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Wczytanie danych uczących i testowych (dość długo trwa).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] loading training and testing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-b4cfed2cd08d>\u001b[0m in \u001b[0;36mload_split\u001b[0;34m(basePath, csvPath)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Wczytanie zawartości pliku CVS z opisem danych, pominięcie pierwszej linii.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Wymieszanie przykładów uczących\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gtsrb//Train.csv'"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"bTuFQ4cXoHcu","executionInfo":{"status":"aborted","timestamp":1705327608877,"user_tz":-60,"elapsed":9,"user":{"displayName":"xy z","userId":"08668859455928206610"}}},"source":["# Przygotowanie do uczenia modelu\n","\n","# Liczba etykiet\n","numLabels = trainY.shape[1]\n","\n","# Liczba epok (iteracji algorytmu uczenia)\n","NUM_EPOCHS = 15\n","\n","# Współczynnik uczenia\n","INIT_LR = 1e-3\n","\n","# Rozmiar \"wsadu\" do batch normalization (https://en.wikipedia.org/wiki/Batch_normalization)\n","BS = 64\n","\n","# Wczytanie zbioru uczącego i testowego\n","with open('train_test.pickle', 'rb') as f:\n","    trainX, trainY, testX, testY = pickle.load(f)\n","\n","# Stworzenie obiektu do augumentacji danych\n","# Co to jest augumentacja ?\n","# Ogólnie jest to \"sztuczne\" zwiększenie liczebności zbioru uczącego.\n","# Jak można się domyśleć po nazwach, tu obejmuje takie operacje jak: obrót, skalowanie, przesunięcie, czy zniekształcenie.\n","aug = ImageDataGenerator(\n","\trotation_range=10,\n","\tzoom_range=0.15,\n","\twidth_shift_range=0.1,\n","\theight_shift_range=0.1,\n","\tshear_range=0.15,\n","\thorizontal_flip=False,\n","\tvertical_flip=False,\n","\tfill_mode=\"nearest\")\n","\n","# Inicjalizacja optymalizatora oraz kompilacja modułu\n","# Parameter LR (Learning Rate) mówi nam o tym, jak bardzo sieć się uczy (jak bardzo możemy zmienić paramtery z danym kroku).\n","# Proszę zwrócić uwagę, że ustawia się również jego zanikanie (decay).\n","# Upraszczając (znowu). W poszukiwaniu optimum lokalnego, w przestrzeni rozwiązań (bo do tego ostatecznie sprowadza się problem uczenia), na początu dopuszczamy duże przesunięcia, a z czasem coraz mniejsze.\n","\n","print(\"[INFO] compiling model...\")\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n","model = TrafficSignNet.build(width=32, height=32, depth=3,\n","\tclasses=numLabels)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])\n","\n","# Wyliczanie wag dla klas -> wskazanie dla modułu, że występuje problem z różną liczebnością zbioru uczącego.\n","classTotals = trainY.sum(axis=0)\n","classWeight = classTotals.max() / classTotals\n","classWeightD = {x: classWeight[x] for x in range(0,classWeight.shape[0]) }\n","\n","print(\"[INFO] model ready to learn...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"AwqyyiSOoHcv","executionInfo":{"status":"aborted","timestamp":1705327608877,"user_tz":-60,"elapsed":8,"user":{"displayName":"xy z","userId":"08668859455928206610"}}},"source":["# Uczenie modelu\n","# To może chwile trwać - ograniczyliśmy liczbę epok (iteracji procesu do 15).\n","# Ogólnie jest to etap, który dobrze można akcelerować na GPU.\n","# Przy czym lokalna konfiguracja TensorFlow/Keras do współpracy z GPU nie jest prosta (i na pewno trwa znacznie dłużej niż to uczenie :)).\n","# W kolejnych epokach wyświetlają się wskaźniki\n","# - accuracy - dokładność na zbiorze uczącym (ma rosnąć)\n","# - loss - funkcja błędu dla zbioru uczącego (ma maleć)\n","# - val_accuracy - dokładność dla zbioru walidacyjnego (ma rosnąć)\n","# - val_loss - funkcja błędu  na zbiorze walidacyjnym (ma maleć)\n","\n","# Zbiory uczące i testowe są rozłączne, aby móc zaobserwować zjawisko \"przeuczenia\" modelu (ang. overfitting).\n","# Najkrócej ujmując - jest to analogia nauki na pamięć. Model dobrze nauczy się danych uczących, a kiepsko będzie sobie radził na innych.\n","\n","\n","\n","print(\"[INFO] training network...\")\n","H = model.fit_generator(\n","\taug.flow(trainX, trainY, batch_size=BS),\n","\tvalidation_data=(testX, testY),\n","\tsteps_per_epoch=trainX.shape[0] // BS,\n","\tepochs=NUM_EPOCHS,\n","\tclass_weight=classWeightD,\n","\tverbose=1)\n","\n","# Zapis sieci na dysk - coby nie trzeba drugi raz uczyć.\n","print(\"[INFO] serializing network to '{}'... trafficsignnet.model\")\n","model.save(\"trafficsignnet.model\")\n","\n","\n","print(\"[INFO] training network done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"jdlFeBWYoHcw"},"source":["## Ewaluacja\n","\n","Mając dany znak i wynik klasyfikacji mamy 4 możliwości:\n","- TP (True Positive) - wynik klasyfikacji i stan faktyczny są zgodne,\n","- FP (False Positive) - klasyfikacja wskazuje na znak X, ale stan faktyczny to znak Y,\n","- FN (False Negative) - klasyfikacja wskazuje, że to nie znak X, a stan faktyczny to X,\n","- TN (True Negative) - klasyfikacja wskazuje, że to nie znak X i to nie jest znak X.\n","\n","Na tej podstawie można konstruować wskaźniki:\n","- precision = TP / (TP+FP)\n","- recall = TP / (TP+FN)\n","- f1 = 2 * precision*recall / (precision+recall)\n","\n","Szerszy opis na [Wikipedii](https://en.wikipedia.org/wiki/Sensitivity_and_specificity).\n","\n","Parametr *support* oznacza liczbę próbek.\n","\n","Warto na chwilę się zastanowić nad tym, co oznaczają wskaźniki.\n","Precyzja (precision) będzie tym większa, im mniej będzie FP, czyli sytuacji, że znak Y będzie uznany X (należący do ewaluowanej klasy).\n","Natomiast  (recall), będzie tym większa, im miej będzie FN, czyli sytuacji, że znak X (należący na rozpatrywanej klasy) będzie uznany co Y.\n","\n","Należy zwrócić uwagę, że:\n","- w idealnym przypadku (brak błędów) oba powinny być 1,\n","- są poniekąd przeciwstawne - wszystko zależy od tego, czy nasz klasyfikator jest mniej, czy bardziej restrykcyjny.\n","- f1, jakoś średnia harmoniczna, łączy oba wskaźniki.\n","\n","\n","Proszę jeszcze zwrócić uwagę na rysunek `train.png` - wyświetlić i zastanowić się co oznacza.\n","\n","\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"RJ2o_xt9oHcw","executionInfo":{"status":"aborted","timestamp":1705327608877,"user_tz":-60,"elapsed":8,"user":{"displayName":"xy z","userId":"08668859455928206610"}}},"source":["# Ewaluacja modelu (sprawdzenie jak się nauczył)\n","\n","\n","print(\"[INFO] evaluating network...\")\n","predictions = model.predict(testX, batch_size=BS)\n","print(classification_report(testY.argmax(axis=1),\n","\tpredictions.argmax(axis=1), target_names=labelNames))\n","\n","# Wykres funkcji kosztu i dokładności\n","N = np.arange(0, NUM_EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy on Dataset\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(\"train.png\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"bMqlNX73oHcw"},"source":["## Wnioskowanie\n","\n","Jak już mamy nauczony model, to może go użyć do wnioskowania (ang. inference).\n","Wtedy na wejście podajemy zdjęcie znaku, a na wyjściu uzyskujemy informację co to za znak.\n","\n","Uwaga. Proszę utworzyć folder `examples`.\n","\n","Na samym końcu patrzymy co nam wyszło.\n","Z uwagi na ograniczaną liczbę iteracji - \"szału nie ma\", ale i tak znaki o lepszej jakości powinny być rozpoznane poprawnie.\n","\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Uo4OyWP9oHcx","executionInfo":{"status":"aborted","timestamp":1705327608877,"user_tz":-60,"elapsed":8,"user":{"displayName":"xy z","userId":"08668859455928206610"}}},"source":["from tensorflow.keras.models import load_model\n","from skimage import transform\n","from skimage import exposure\n","from skimage import io\n","from imutils import paths\n","import numpy as np\n","import imutils\n","import random\n","import cv2\n","import os\n","\n","# Wczytujemy model\n","print(\"[INFO] loading model...\")\n","model = load_model(\"trafficsignnet.model\")\n","# Wczytujemy nazwy klas (ponownie)\n","labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n","labelNames = [l.split(\",\")[0] for l in labelNames]\n","# Wczytujemy obrazy, mieszamy, wybieramy podzbiór:\n","print(\"[INFO] predicting...\")\n","imagePaths = list(paths.list_images(\"gtsrb/Test\"))\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:25]\n","\n","# Pętla po obrazach\n","for (i, imagePath) in enumerate(imagePaths):\n","\t# Wczytujemy obraz, skalujemy, wyrównujemy histogram - dokładnie jak wcześniej\n","\n","\timage = io.imread(imagePath)\n","\timage = transform.resize(image, (32, 32))\n","\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n","\t# Skalujemy do wartości 0,1\n","\timage = image.astype(\"float32\") / 255.0\n","\timage = np.expand_dims(image, axis=0)\n","\n","\t# Przeprowadzamy wnioskowanie\n","\tpreds = model.predict(image)\n","\t# Wybieramy największą odpowedź\n","\tj = preds.argmax(axis=1)[0]\n","\tlabel = labelNames[j]\n","\n","\t# Wizualizacja i zapis do pliku\n","\timage = cv2.imread(imagePath)\n","\timage = imutils.resize(image, width=128)\n","\tcv2.putText(image, label, (5, 15), cv2.FONT_HERSHEY_SIMPLEX,\n","\t\t0.45, (0, 0, 255), 2)\n","\tp = os.path.sep.join([\"examples\", \"{}.png\".format(i)])\n","\tcv2.imwrite(p, image)\n","\n","print(\"[INFO] done...\")"],"execution_count":null,"outputs":[]}]}